{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import netCDF4 as nc4\n",
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-trail",
   "metadata": {},
   "source": [
    "List the deployments that have been manually labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_dir = \"/Users/frank/Box/Research/1 In progress/Gas exchange/Breathing ethogram/\"\n",
    "available_data = pd.read_excel(box_dir + \"BreathingVideo.xlsx\", \n",
    "                               engine=\"openpyxl\",\n",
    "                               sheet_name=\"Overview\",\n",
    "                               index_col=0)\n",
    "available_data = available_data[available_data.index.str.contains('[A-z]{2}[0-9]{6}') == True]\n",
    "available_data[[\"aligned\", \"prh_nc\"]] = available_data[[\"aligned\", \"prh_nc\"]].astype(bool)\n",
    "available_data = available_data.query(\"aligned & prh_nc\")\n",
    "available_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-counter",
   "metadata": {},
   "source": [
    "Pick a deployment and read the PRH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_id = \"be180423-42\"\n",
    "nc_path = glob(\"/Volumes/COPYCATSdat/CATS/tag_data/prh/{}*.nc\".format(export_id))\n",
    "print(nc_path)\n",
    "prh_nc = nc4.Dataset(nc_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "whale_tz = \"Etc/GMT%+i\" % -prh_nc.dephist_device_tzone\n",
    "dt = pd.to_datetime(np.array(prh_nc[\"DN\"]) - 719529, unit=\"D\", utc=True).tz_convert(whale_tz)\n",
    "depth, pitch, roll = [np.array(prh_nc[var]) for var in [\"P\", \"pitch\", \"roll\"]]\n",
    "jerk = np.sum(np.diff(np.array(prh_nc[\"Aw\"]), append=np.nan) ** 2, axis=0)\n",
    "prh_data = pd.DataFrame(index=dt, data={\"depth\": depth, \"pitch\": pitch, \"roll\": roll, \"jerk\": jerk})\n",
    "prh_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(prh_data.index, -prh_data[\"depth\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-pittsburgh",
   "metadata": {},
   "source": [
    "Match video coverage to PRH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_coverage = pd.read_excel(box_dir + \"BreathingVideo.xlsx\", \n",
    "                               engine=\"openpyxl\",\n",
    "                               sheet_name=\"Time alignment\",\n",
    "                               index_col=0,\n",
    "                               converters = {\"boristime1\": str, \"boristime2\": str}).loc[export_id]\n",
    "for col in [\"camtime1\", \"camtime2\"]:\n",
    "    video_coverage[col] = video_coverage[col].dt.tz_localize(whale_tz)\n",
    "for col in [\"boristime1\", \"boristime2\"]:\n",
    "    video_coverage[col] = pd.to_timedelta(video_coverage[col]).dt.total_seconds()\n",
    "\n",
    "video_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(prh_data.index, -prh_data[\"depth\"])\n",
    "for row in range(len(video_coverage)):\n",
    "    plt.axvspan(video_coverage[\"camtime1\"].iloc[row], \n",
    "                video_coverage[\"camtime2\"].iloc[row],\n",
    "                color=\"y\", alpha = 0.5, lw=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-forth",
   "metadata": {},
   "source": [
    "Pick out a sample and highlight labeled breaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_start, sample_end = \"2019-02-28 09:17:56\", \"2019-02-28 12:49:06\"\n",
    "sample_data = prh_data.loc[sample_start:sample_end]\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(sample_data.index, -sample_data[\"depth\"])\n",
    "is_overlap = np.logical_and(video_coverage[\"camtime1\"] < sample_end, \n",
    "                            video_coverage[\"camtime2\"] > sample_start)\n",
    "overlap_vids = video_coverage[is_overlap]\n",
    "for row in range(len(overlap_vids)):\n",
    "    plt.axvspan(overlap_vids[\"camtime1\"].iloc[row], \n",
    "                overlap_vids[\"camtime2\"].iloc[row],\n",
    "                facecolor=\"y\", alpha=0.5, lw=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boristime_to_camtime(boristime):\n",
    "        def interleave(l1, l2):\n",
    "            result = l1 + l2\n",
    "            result[::2] = l1\n",
    "            result[1::2] = l2\n",
    "            return result\n",
    "\n",
    "        xs = interleave(list(video_coverage[\"boristime1\"]), list(video_coverage[\"boristime2\"]))\n",
    "        ys = interleave(list(video_coverage[\"camtime1\"]), list(video_coverage[\"camtime2\"]))\n",
    "        min_y = np.min(ys)\n",
    "        ys_float = pd.Series(np.subtract(ys, min_y)).dt.total_seconds()\n",
    "        camtime_float = np.interp(boristime, xs, ys_float)\n",
    "        return min_y + pd.to_timedelta(camtime_float, unit=\"s\")\n",
    "    \n",
    "breath_data = pd.read_csv(box_dir + \"breaths.csv\", \n",
    "                          index_col=0, \n",
    "                          usecols=[0, 3, 11, 12]).loc[export_id]\n",
    "breath_data[\"breath_start\"] = boristime_to_camtime(breath_data[\"Start (s)\"])\n",
    "breath_data[\"breath_end\"] = boristime_to_camtime(breath_data[\"Stop (s)\"])\n",
    "\n",
    "breaths = breath_data[\"breath_start\"] + (breath_data[\"breath_start\"] - breath_data[\"breath_end\"]) / 2\n",
    "breaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_breaths = breaths[np.logical_and(breaths > sample_start, breaths < sample_end)]\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(sample_data.index, -sample_data[\"depth\"])\n",
    "is_overlap = np.logical_and(video_coverage[\"camtime1\"] < sample_end, \n",
    "                            video_coverage[\"camtime2\"] > sample_start)\n",
    "overlap_vids = video_coverage[is_overlap]\n",
    "for row in range(len(overlap_vids)):\n",
    "    plt.axvspan(overlap_vids[\"camtime1\"].iloc[row], \n",
    "                overlap_vids[\"camtime2\"].iloc[row],\n",
    "                facecolor=\"y\", alpha=0.5, lw=0)\n",
    "for i in range(len(overlap_breaths)):\n",
    "    plt.axvline(overlap_breaths[i], color=\"r\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\"{}\\\": (\\\"{}\\\", \\\"{}\\\")\".format(export_id, sample_start, sample_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "export = {\n",
    "    \"bb180125-30\": (\"2018-01-25 16:00:18\", \"2018-01-25 17:00:16\"),\n",
    "    \"bb190309-52\": (\"2019-03-09 12:10:00\", \"2019-03-09 12:40:00\"),\n",
    "    \"be180423-42\": (\"2018-04-23 10:53:00\", \"2018-04-23 15:37:45\"),\n",
    "    \"bp180526-42\": (\"2018-05-26 13:00:07\", \"2018-05-26 16:39:38\"),\n",
    "    \"bp180526-44\": (\"2018-05-26 11:57:57\", \"2018-05-26 17:01:32\"),\n",
    "    \"bs190322-47\": (\"2019-03-22 15:18:30\", \"2019-03-22 17:01:00\"),\n",
    "    \"bs190322-49\": (\"2019-03-22 18:15:36\", \"2019-03-22 18:45:23\"),\n",
    "    \"bw180828-49\": (\"2018-08-28 11:52:50\", \"2018-08-28 19:27:28\"),\n",
    "    \"bw180904-48\": (\"2018-09-04 11:17:33\", \"2018-09-04 14:57:00\"),\n",
    "    \"bw180905-53\": (\"2018-09-05 11:55:07\", \"2018-09-05 13:20:01\"),\n",
    "    \"er160505-25\": (\"2016-05-05 13:54:58\", \"2016-05-05 18:04:23\"),\n",
    "    \"mn170810-42\": (\"2017-08-10 11:17:51\", \"2017-08-10 16:30:52\"),\n",
    "    \"mn170815-20\": (\"2017-08-15 12:31:52\", \"2017-08-15 13:42:36\"),\n",
    "    \"mn190228-42\": (\"2019-02-28 09:17:54\", \"2019-02-28 12:49:03\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "prh_all, breaths_all = pd.DataFrame(), pd.MultiIndex.from_arrays([[], []])\n",
    "for deployid, (starttime, stoptime) in export.items():\n",
    "    print(\"{}: {} - {}\".format(deployid, starttime, stoptime))\n",
    "    # load prh\n",
    "    nc_path = glob(\"/Volumes/COPYCATSdat/CATS/tag_data/prh/{}*.nc\".format(deployid))\n",
    "    prh_nc = nc4.Dataset(nc_path[0])\n",
    "    whale_tz = \"Etc/GMT%+i\" % -prh_nc.dephist_device_tzone\n",
    "    dt = pd.to_datetime(np.array(prh_nc[\"DN\"]) - 719529, unit=\"D\", utc=True).tz_convert(whale_tz)\n",
    "    depth, pitch, roll = [np.array(prh_nc[var]) for var in [\"P\", \"pitch\", \"roll\"]]\n",
    "    jerk = np.sum(np.diff(np.array(prh_nc[\"Aw\"]), append=np.nan) ** 2, axis=0)\n",
    "    prh_data = pd.DataFrame(index=dt, data={\"depth\": depth, \"pitch\": pitch, \"roll\": roll, \"jerk\": jerk})\n",
    "    \n",
    "    # load breaths\n",
    "    video_coverage = pd.read_excel(box_dir + \"BreathingVideo.xlsx\", \n",
    "                                   engine=\"openpyxl\",\n",
    "                                   sheet_name=\"Time alignment\",\n",
    "                                   index_col=0,\n",
    "                                   converters = {\"boristime1\": str, \"boristime2\": str}).loc[deployid]\n",
    "    for col in [\"camtime1\", \"camtime2\"]:\n",
    "        video_coverage[col] = video_coverage[col].dt.tz_localize(whale_tz)\n",
    "    for col in [\"boristime1\", \"boristime2\"]:\n",
    "        video_coverage[col] = pd.to_timedelta(video_coverage[col]).dt.total_seconds()\n",
    "    def boristime_to_camtime(boristime):\n",
    "        def interleave(l1, l2):\n",
    "            result = l1 + l2\n",
    "            result[::2] = l1\n",
    "            result[1::2] = l2\n",
    "            return result\n",
    "\n",
    "        xs = interleave(list(video_coverage[\"boristime1\"]), list(video_coverage[\"boristime2\"]))\n",
    "        ys = interleave(list(video_coverage[\"camtime1\"]), list(video_coverage[\"camtime2\"]))\n",
    "        min_y = np.min(ys)\n",
    "        ys_float = pd.Series(np.subtract(ys, min_y)).dt.total_seconds()\n",
    "        camtime_float = np.interp(boristime, xs, ys_float)\n",
    "        return min_y + pd.to_timedelta(camtime_float, unit=\"s\")\n",
    "    breath_data = pd.read_csv(box_dir + \"breaths.csv\", \n",
    "                              index_col=0, \n",
    "                              usecols=[0, 3, 11, 12]).loc[deployid]\n",
    "    breath_data[\"breath_start\"] = boristime_to_camtime(breath_data[\"Start (s)\"])\n",
    "    breath_data[\"breath_end\"] = boristime_to_camtime(breath_data[\"Stop (s)\"])\n",
    "\n",
    "    breaths = breath_data[\"breath_start\"] + (breath_data[\"breath_start\"] - breath_data[\"breath_end\"]) / 2\n",
    "    \n",
    "    # subset and append\n",
    "    sample_data = prh_data.loc[starttime:stoptime]\n",
    "    sample_data.index = pd.MultiIndex.from_product([[deployid], sample_data.index])\n",
    "    sample_breaths = breaths[np.logical_and(breaths > starttime, breaths < stoptime)]\n",
    "    sample_breaths = pd.MultiIndex.from_product([[deployid], sample_breaths])\n",
    "    prh_all = prh_all.append(sample_data)\n",
    "    breaths_all = breaths_all.union(sample_breaths)\n",
    "prh_all.index.names = [\"deployid\", \"time\"]\n",
    "breaths_all.names = [\"deployid\", \"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(prh_all.reset_index())\n",
    "def duration_hrs(t: pd.Series):\n",
    "    return (t.iloc[-1] - t.iloc[0]).total_seconds() / 3600\n",
    "prh_summ = prh_all.reset_index().groupby(\"deployid\").agg({\"time\": [duration_hrs]})\n",
    "breath_summ = breaths_all.to_series().groupby(\"deployid\").agg(\"count\")\n",
    "summ = pd.concat([prh_summ, breath_summ], axis=1)\n",
    "summ.columns = [\"Duration (hrs)\", \"Breaths (count)\"]\n",
    "summ.loc[\"Total\"] = summ.sum()\n",
    "display(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be none\n",
    "display(prh_all[prh_all.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "prh_all.to_pickle(\"../data/multi_prh.pkl\")\n",
    "pd.Series(True, index=breaths_all, name=\"event\").to_pickle(\"../data/multi_breaths.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-invite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stickleback",
   "language": "python",
   "name": "stickleback"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
